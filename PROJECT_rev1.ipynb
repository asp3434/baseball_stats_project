{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Acquisition\n",
    "www.baseball-reference.com only allows 20 requests per minute. If we violate this rule, our session will be locked out for one hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# request website for each year\n",
    "main_url = 'https://www.baseball-reference.com'\n",
    "years = ['2019', '2021', '2022']\n",
    "pages = []\n",
    "soups = []\n",
    "for i in range(len(years)):\n",
    "    url = f'{main_url}/leagues/majors/{years[i]}.shtml'\n",
    "    page = requests.get(url)\n",
    "    pages.append(page)\n",
    "    soups.append(BeautifulSoup(page.content))\n",
    "    \n",
    "# three requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through soups to get the winning team links\n",
    "pattern = '/teams/[A-Z][A-Z][A-Z]/20[0-9][0-9].shtml'\n",
    "winning_team_links = []\n",
    "for k in range(len(soups)):\n",
    "    hrefs = soups[k].find_all('a', href=True)\n",
    "    for i in range(len(hrefs)):\n",
    "        new_str = str(hrefs[i])\n",
    "        check = re.search(pattern, new_str)\n",
    "        if check:\n",
    "            link = new_str[9:30]  \n",
    "            break\n",
    "    winning_team_links.append(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# request website for each winning team\n",
    "win_team_pages = []\n",
    "win_team_soups = []\n",
    "for i in range(len(winning_team_links)):\n",
    "    url = f'{main_url}{winning_team_links[i]}'\n",
    "    page = requests.get(url)\n",
    "    win_team_pages.append(page)\n",
    "    win_team_soups.append(BeautifulSoup(page.content))\n",
    "    \n",
    "# three requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pandas dataframes for team stats that won the world series\n",
    "batting_team_stats = []\n",
    "pitching_team_stats = []\n",
    "for i in range(len(win_team_pages)):\n",
    "    [batting, pitching] = pd.read_html(win_team_pages[i].content)\n",
    "    batting_team_stats.append(batting)\n",
    "    pitching_team_stats.append(pitching)\n",
    "\n",
    "# need to delete row index 8 in most (if not all) dataframes for batting. Also delete the last 5 rows.\n",
    "# delete index row 5, 11, and last 3 rows in pitching. Look at each dataframe before making edits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through table to get link for each player of each team that won World Series\n",
    "player_links = []\n",
    "for k in range(len(win_team_soups)):\n",
    "    team_pl_links = []\n",
    "    counter =0\n",
    "    for this_soup in win_team_soups[k].find_all('td', {\"class\": \"left\", \"data-stat\": \"player\"}):\n",
    "        try:\n",
    "            counter += 1\n",
    "            link = this_soup.find('a')['href']\n",
    "            team_pl_links.append(link)\n",
    "            if counter >= 9:\n",
    "                break\n",
    "        except:\n",
    "            pass\n",
    "    player_links.append(team_pl_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/players/g/gomesya01.shtml', '/players/a/adamsma01.shtml', '/players/d/doziebr01.shtml', '/players/t/turnetr01.shtml', '/players/r/rendoan01.shtml', '/players/s/sotoju01.shtml', '/players/r/roblevi01.shtml', '/players/e/eatonad02.shtml', '/players/k/kendrho01.shtml']\n"
     ]
    }
   ],
   "source": [
    "print(player_links[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
